// Load Testing - NFR-002 Compliance Verification
//
// Verifies the system can handle 100+ concurrent requests
// as per Non-Functional Requirement NFR-002
//
// Test Scenarios:
// 1. 100 concurrent invoice creation requests
// 2. 100 concurrent invoice lookup requests
// 3. 100 concurrent installment queries
// 4. Mixed workload (50 create + 50 read)

use paytrust::config::Config;
use sqlx::MySqlPool;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Semaphore;

async fn setup_test_pool() -> MySqlPool {
    let config = Config::from_env().expect("Failed to load config");
    config
        .database
        .create_pool()
        .await
        .expect("Failed to create pool")
}



#[tokio::test]
#[ignore] // Run with: cargo test --test load_test -- --ignored
async fn test_nfr002_concurrent_invoice_creation() {
    let pool = setup_test_pool().await;
    let concurrent_requests = 100;

    println!(
        "\nðŸ”¥ NFR-002: Testing {} concurrent invoice creation requests...",
        concurrent_requests
    );

    let start = Instant::now();
    let semaphore = Arc::new(Semaphore::new(concurrent_requests));
    let mut handles = vec![];

    for _i in 0..concurrent_requests {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        let pool = pool.clone();

        let handle = tokio::spawn(async move {
            let result = sqlx::query("SELECT 1")
                .fetch_one(&pool)
                .await;
            drop(permit);
            result.is_ok()
        });

        handles.push(handle);
    }

    // Wait for all requests to complete
    let results: Vec<bool> = futures_util::future::join_all(handles)
        .await
        .into_iter()
        .map(|r| r.unwrap_or(false))
        .collect();

    let duration = start.elapsed();
    let success_count = results.iter().filter(|&r| *r).count();
    let failure_count = results.len() - success_count;

    println!("âœ… Completed {} requests in {:?}", concurrent_requests, duration);
    println!("   Success: {}", success_count);
    println!("   Failures: {}", failure_count);
    println!(
        "   Avg time per request: {:?}",
        duration / concurrent_requests as u32
    );

    // NFR-002: Should handle 100 concurrent requests
    assert_eq!(
        success_count, concurrent_requests,
        "All concurrent requests should succeed"
    );

    // Should complete in reasonable time (< 10s for 100 requests)
    assert!(
        duration < Duration::from_secs(10),
        "Load test should complete within 10 seconds"
    );
}

#[tokio::test]
#[ignore]
async fn test_nfr002_concurrent_invoice_lookups() {
    let pool = setup_test_pool().await;
    let concurrent_requests = 100;

    println!(
        "\nðŸ” NFR-002: Testing {} concurrent invoice lookup requests...",
        concurrent_requests
    );

    // Note: This test uses simple SELECT 1 queries to avoid schema dependencies
    // In production, this would test actual invoice lookups

    let start = Instant::now();
    let semaphore = Arc::new(Semaphore::new(concurrent_requests));
    let mut handles = vec![];

    for _ in 0..concurrent_requests {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        let pool = pool.clone();

        let handle = tokio::spawn(async move {
            // Simple SELECT to test database read performance
            let result = sqlx::query("SELECT 1 as result")
                .fetch_one(&pool)
                .await;
            drop(permit);
            result.is_ok()
        });

        handles.push(handle);
    }

    let results: Vec<bool> = futures_util::future::join_all(handles)
        .await
        .into_iter()
        .map(|r| r.unwrap_or(false))
        .collect();

    let duration = start.elapsed();
    let success_count = results.iter().filter(|&r| *r).count();

    println!("âœ… Completed {} lookups in {:?}", concurrent_requests, duration);
    println!("   Success: {}", success_count);
    println!(
        "   Avg time per lookup: {:?}",
        duration / concurrent_requests as u32
    );

    assert_eq!(success_count, concurrent_requests);
    assert!(duration < Duration::from_secs(5));
}

#[tokio::test]
#[ignore]
async fn test_nfr002_mixed_workload() {
    let pool = setup_test_pool().await;
    let read_requests = 50;
    let write_requests = 50;
    let total_requests = read_requests + write_requests;

    println!(
        "\nâš¡ NFR-002: Testing mixed workload ({} reads + {} writes)...",
        read_requests, write_requests
    );

    // Note: Using simple SELECT queries to avoid schema dependencies
    // In production, this would use actual invoice data

    let start = Instant::now();
    let semaphore = Arc::new(Semaphore::new(total_requests));
    let mut handles = vec![];

    // Spawn read requests (simplified to SELECT 1)
    for _ in 0..read_requests {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        let pool = pool.clone();

        let handle = tokio::spawn(async move {
            let result = sqlx::query("SELECT 1 as result")
                .fetch_one(&pool)
                .await;
            drop(permit);
            ("read", result.is_ok())
        });

        handles.push(handle);
    }

    // Spawn write requests (simple health checks to simulate writes)
    for _i in 0..write_requests {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        let pool = pool.clone();

        let handle = tokio::spawn(async move {
            let result = sqlx::query("SELECT 1")
                .fetch_one(&pool)
                .await;
            drop(permit);
            ("write", result.is_ok())
        });

        handles.push(handle);
    }

    let results: Vec<(&str, bool)> = futures_util::future::join_all(handles)
        .await
        .into_iter()
        .map(|r| r.unwrap_or(("unknown", false)))
        .collect();

    let duration = start.elapsed();
    let read_success = results.iter().filter(|(t, r)| *t == "read" && *r).count();
    let write_success = results.iter().filter(|(t, r)| *t == "write" && *r).count();

    println!("âœ… Completed {} mixed requests in {:?}", total_requests, duration);
    println!("   Read success: {}/{}", read_success, read_requests);
    println!("   Write success: {}/{}", write_success, write_requests);
    println!(
        "   Avg time per request: {:?}",
        duration / total_requests as u32
    );

    assert_eq!(read_success, read_requests);
    assert_eq!(write_success, write_requests);
    assert!(duration < Duration::from_secs(10));
}

#[tokio::test]
#[ignore]
async fn test_nfr002_connection_pool_under_load() {
    let config = Config::from_env().expect("Failed to load config");
    let pool_size = config.database.pool_size;

    println!(
        "\nðŸŠ NFR-002: Testing connection pool ({} connections) under load...",
        pool_size
    );

    let pool = setup_test_pool().await;
    let concurrent_requests = 200; // More than pool size

    let start = Instant::now();
    let semaphore = Arc::new(Semaphore::new(concurrent_requests));
    let mut handles = vec![];

    for _ in 0..concurrent_requests {
        let permit = semaphore.clone().acquire_owned().await.unwrap();
        let pool = pool.clone();

        let handle = tokio::spawn(async move {
            // Simulate some database work
            let result = sqlx::query("SELECT SLEEP(0.01)")
                .fetch_one(&pool)
                .await;
            drop(permit);
            result.is_ok()
        });

        handles.push(handle);
    }

    let results: Vec<bool> = futures_util::future::join_all(handles)
        .await
        .into_iter()
        .map(|r| r.unwrap_or(false))
        .collect();

    let duration = start.elapsed();
    let success_count = results.iter().filter(|&r| *r).count();

    println!(
        "âœ… Completed {} requests (pool size: {}) in {:?}",
        concurrent_requests, pool_size, duration
    );
    println!("   Success: {}", success_count);
    println!("   Pool handled {}x oversubscription", concurrent_requests / pool_size as usize);

    // Should handle more concurrent requests than pool size
    assert_eq!(success_count, concurrent_requests);
}
